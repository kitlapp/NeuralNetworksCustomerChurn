{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5d1fcd0b-99d4-4927-ab46-46281a2334b2",
   "metadata": {},
   "source": [
    "# Notebook Description"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20f5535e-9673-4405-b3d9-3a1c2df17934",
   "metadata": {},
   "source": [
    "<div style=\"text-align: justify\">\n",
    "The notebook named 'Audiobooks.ipynb' demonstrates my hands-on critical thinking in creating a neural network model to predict whether a person will repurchase an audiobook. Seeing that I couldn't easily beat the baseline with my version of the neural network, I decided to copy and paste the instructor's code into a new notebook to run and test its results. Finally, I will compare the instructor's code results with my results to see how my approach works in comparison.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "914df4e2-628c-4cce-b783-b35866a01668",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys \n",
    "sys.executable  # Display the path to the Python executable ensuring the correct env"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0e42ce0-e23c-4dae-8f5c-ca82b325e5af",
   "metadata": {},
   "source": [
    "<div style=\"text-align: justify\">\n",
    "This is the last cell I intervene in this notebook. The cells below present the instructor's point of view. I have included two different data files in this project to ensure the code and files match those the instructor used. We want to test its results completely unbiased. My only intervention is that I will delete all instructor comments, as they don't affect the results.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbf0f321-6fd4-4acb-b0ef-5335b92e1d90",
   "metadata": {},
   "source": [
    "# Here Starts the Instructor's Point of View:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "id": "dd31891c-1e2e-47e5-a162-9e9320f00304",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn import preprocessing\n",
    "\n",
    "raw_csv_data = np.loadtxt('Audiobooks_data.csv',delimiter=',')\n",
    "\n",
    "unscaled_inputs_all = raw_csv_data[:,1:-1]\n",
    "\n",
    "targets_all = raw_csv_data[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "id": "885587dd-79b7-4e52-8cef-2d491b51be00",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_one_targets = int(np.sum(targets_all))\n",
    "\n",
    "zero_targets_counter = 0\n",
    "\n",
    "indices_to_remove = []\n",
    "\n",
    "for i in range(targets_all.shape[0]):\n",
    "    if targets_all[i] == 0:\n",
    "        zero_targets_counter += 1\n",
    "        if zero_targets_counter > num_one_targets:\n",
    "            indices_to_remove.append(i)\n",
    "            \n",
    "unscaled_inputs_equal_priors = np.delete(unscaled_inputs_all, indices_to_remove, axis=0)\n",
    "targets_equal_priors = np.delete(targets_all, indices_to_remove, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "id": "b238ddfb-6acc-4e9a-9b67-7449e4a53503",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled_inputs = preprocessing.scale(unscaled_inputs_equal_priors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "id": "2d0b7a9e-69b3-4947-97f2-0444765d0046",
   "metadata": {},
   "outputs": [],
   "source": [
    "shuffled_indices = np.arange(scaled_inputs.shape[0])\n",
    "np.random.shuffle(shuffled_indices)\n",
    "\n",
    "shuffled_inputs = scaled_inputs[shuffled_indices]\n",
    "shuffled_targets = targets_equal_priors[shuffled_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "id": "d5895d65-f815-47f0-bdba-ed618002b55b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1773.0 3579 0.4953897736797988\n",
      "234.0 447 0.5234899328859061\n",
      "230.0 448 0.5133928571428571\n"
     ]
    }
   ],
   "source": [
    "samples_count = shuffled_inputs.shape[0]\n",
    "\n",
    "train_samples_count = int(0.8 * samples_count)\n",
    "validation_samples_count = int(0.1 * samples_count)\n",
    "\n",
    "test_samples_count = samples_count - train_samples_count - validation_samples_count\n",
    "\n",
    "train_inputs = shuffled_inputs[:train_samples_count]\n",
    "train_targets = shuffled_targets[:train_samples_count]\n",
    "\n",
    "validation_inputs = shuffled_inputs[train_samples_count:train_samples_count+validation_samples_count]\n",
    "validation_targets = shuffled_targets[train_samples_count:train_samples_count+validation_samples_count]\n",
    "\n",
    "test_inputs = shuffled_inputs[train_samples_count+validation_samples_count:]\n",
    "test_targets = shuffled_targets[train_samples_count+validation_samples_count:]\n",
    "\n",
    "print(np.sum(train_targets), train_samples_count, np.sum(train_targets) / train_samples_count)\n",
    "print(np.sum(validation_targets), validation_samples_count, np.sum(validation_targets) / validation_samples_count)\n",
    "print(np.sum(test_targets), test_samples_count, np.sum(test_targets) / test_samples_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "id": "6a8ec467-8c85-4f9c-a987-1d28a8c0ea89",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savez('Audiobooks_data_train', inputs=train_inputs, targets=train_targets)\n",
    "np.savez('Audiobooks_data_validation', inputs=validation_inputs, targets=validation_targets)\n",
    "np.savez('Audiobooks_data_test', inputs=test_inputs, targets=test_targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "id": "92796008-3981-4890-ad60-ef973f98f657",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "id": "fb51e90e-a948-4ed4-b9e7-2686a4ff2952",
   "metadata": {},
   "outputs": [],
   "source": [
    "npz = np.load('Audiobooks_data_train.npz')\n",
    "\n",
    "train_inputs = npz['inputs'].astype(float)\n",
    "\n",
    "train_targets = npz['targets'].astype(int)\n",
    "\n",
    "npz = np.load('Audiobooks_data_validation.npz')\n",
    "\n",
    "validation_inputs, validation_targets = npz['inputs'].astype(float), npz['targets'].astype(int)\n",
    "\n",
    "npz = np.load('Audiobooks_data_test.npz')\n",
    "\n",
    "test_inputs, test_targets = npz['inputs'].astype(float), npz['targets'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "id": "deab400a-cd79-4eef-87fa-9aebbcb2aade",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "36/36 - 1s - 21ms/step - accuracy: 0.6837 - loss: 0.5670 - val_accuracy: 0.7718 - val_loss: 0.4649\n",
      "Epoch 2/100\n",
      "36/36 - 0s - 1ms/step - accuracy: 0.7502 - loss: 0.4677 - val_accuracy: 0.8121 - val_loss: 0.3930\n",
      "Epoch 3/100\n",
      "36/36 - 0s - 1ms/step - accuracy: 0.7762 - loss: 0.4213 - val_accuracy: 0.8277 - val_loss: 0.3596\n",
      "Epoch 4/100\n",
      "36/36 - 0s - 1ms/step - accuracy: 0.7770 - loss: 0.3962 - val_accuracy: 0.8479 - val_loss: 0.3407\n",
      "Epoch 5/100\n",
      "36/36 - 0s - 1ms/step - accuracy: 0.7932 - loss: 0.3795 - val_accuracy: 0.8345 - val_loss: 0.3258\n",
      "Epoch 6/100\n",
      "36/36 - 0s - 1ms/step - accuracy: 0.7983 - loss: 0.3687 - val_accuracy: 0.8591 - val_loss: 0.3158\n",
      "Epoch 7/100\n",
      "36/36 - 0s - 1ms/step - accuracy: 0.8097 - loss: 0.3596 - val_accuracy: 0.8389 - val_loss: 0.3099\n",
      "Epoch 8/100\n",
      "36/36 - 0s - 1ms/step - accuracy: 0.8078 - loss: 0.3545 - val_accuracy: 0.8367 - val_loss: 0.3021\n",
      "Epoch 9/100\n",
      "36/36 - 0s - 1ms/step - accuracy: 0.8055 - loss: 0.3512 - val_accuracy: 0.8300 - val_loss: 0.3012\n",
      "Epoch 10/100\n",
      "36/36 - 0s - 1ms/step - accuracy: 0.8097 - loss: 0.3459 - val_accuracy: 0.8523 - val_loss: 0.2913\n",
      "Epoch 11/100\n",
      "36/36 - 0s - 1ms/step - accuracy: 0.8136 - loss: 0.3438 - val_accuracy: 0.8479 - val_loss: 0.2901\n",
      "Epoch 12/100\n",
      "36/36 - 0s - 1ms/step - accuracy: 0.8153 - loss: 0.3423 - val_accuracy: 0.8389 - val_loss: 0.2947\n",
      "Epoch 13/100\n",
      "36/36 - 0s - 1ms/step - accuracy: 0.8206 - loss: 0.3370 - val_accuracy: 0.8412 - val_loss: 0.2878\n",
      "Epoch 14/100\n",
      "36/36 - 0s - 1ms/step - accuracy: 0.8175 - loss: 0.3369 - val_accuracy: 0.8501 - val_loss: 0.2867\n",
      "Epoch 15/100\n",
      "36/36 - 0s - 1ms/step - accuracy: 0.8215 - loss: 0.3323 - val_accuracy: 0.8434 - val_loss: 0.2878\n",
      "Epoch 16/100\n",
      "36/36 - 0s - 1ms/step - accuracy: 0.8201 - loss: 0.3305 - val_accuracy: 0.8367 - val_loss: 0.2860\n",
      "Epoch 17/100\n",
      "36/36 - 0s - 1ms/step - accuracy: 0.8284 - loss: 0.3291 - val_accuracy: 0.8479 - val_loss: 0.2871\n",
      "Epoch 18/100\n",
      "36/36 - 0s - 1ms/step - accuracy: 0.8203 - loss: 0.3328 - val_accuracy: 0.8479 - val_loss: 0.2826\n",
      "Epoch 19/100\n",
      "36/36 - 0s - 1ms/step - accuracy: 0.8134 - loss: 0.3329 - val_accuracy: 0.8479 - val_loss: 0.2840\n",
      "Epoch 20/100\n",
      "36/36 - 0s - 1ms/step - accuracy: 0.8150 - loss: 0.3287 - val_accuracy: 0.8501 - val_loss: 0.2824\n",
      "Epoch 21/100\n",
      "36/36 - 0s - 1ms/step - accuracy: 0.8265 - loss: 0.3251 - val_accuracy: 0.8367 - val_loss: 0.2824\n",
      "Epoch 22/100\n",
      "36/36 - 0s - 1ms/step - accuracy: 0.8243 - loss: 0.3239 - val_accuracy: 0.8389 - val_loss: 0.2783\n",
      "Epoch 23/100\n",
      "36/36 - 0s - 1ms/step - accuracy: 0.8237 - loss: 0.3243 - val_accuracy: 0.8412 - val_loss: 0.2798\n",
      "Epoch 24/100\n",
      "36/36 - 0s - 1ms/step - accuracy: 0.8273 - loss: 0.3236 - val_accuracy: 0.8523 - val_loss: 0.2876\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x27728326ba0>"
      ]
     },
     "execution_count": 361,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_size = 10\n",
    "output_size = 2\n",
    "\n",
    "hidden_layer_size = 50\n",
    "    \n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(hidden_layer_size, activation='relu'), \n",
    "    tf.keras.layers.Dense(hidden_layer_size, activation='relu'), \n",
    "    \n",
    "    tf.keras.layers.Dense(output_size, activation='softmax') \n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "batch_size = 100\n",
    "\n",
    "max_epochs = 100\n",
    "\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(patience=2)\n",
    "\n",
    "model.fit(train_inputs, \n",
    "          train_targets, \n",
    "          batch_size=batch_size,\n",
    "          epochs=max_epochs, \n",
    "          callbacks=[early_stopping], \n",
    "          validation_data=(validation_inputs, validation_targets), \n",
    "          verbose = 2 \n",
    "          )  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "id": "1e435125-eb1a-4f54-b327-b1baae958b39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 723us/step - accuracy: 0.8349 - loss: 0.3138\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_accuracy = model.evaluate(test_inputs, test_targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "id": "a5f3d214-cd75-4d42-8276-770dd6a21451",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test loss: 0.35. Test accuracy: 81.25%\n"
     ]
    }
   ],
   "source": [
    "print('\\nTest loss: {0:.2f}. Test accuracy: {1:.2f}%'.format(test_loss, test_accuracy*100.))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b8a28a7-b1e5-4330-a288-8925290da2f5",
   "metadata": {},
   "source": [
    "# Here Ends the Instructor's Point of View"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01edf7c8-f55c-450c-8567-c87f4567ff30",
   "metadata": {},
   "source": [
    "# Final Results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac657726-e2c1-45e8-849b-18c6b1803e56",
   "metadata": {},
   "source": [
    "<div style=\"text-align: justify\">\n",
    "I intervene again to keep the instructor's code results for 30 different runs. I don't want to repeat the instructor's model by intervening with the code inside the cells above. Therefore, I will run the notebook until this cell, and then append the results of each run to calculate the average accuracy and loss as well as their standard deviations.  \n",
    "    \n",
    "***Be careful not to run the cell below twice, as it will initialize the lists to empty ones.***\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "122bf003-fabe-4957-9aac-47ceab223345",
   "metadata": {},
   "outputs": [],
   "source": [
    "# BE AWARE NOT TO RUN THIS TWICE:\n",
    "accuracy_list = []\n",
    "loss_list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "id": "f494d549-d45e-41ab-abbc-277a9b92f6e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30"
      ]
     },
     "execution_count": 364,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_list.append(test_accuracy)\n",
    "loss_list.append(test_loss)\n",
    "len(accuracy_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "id": "3bd2d164-55e5-42a3-bce5-9b5825b2dd51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the metrics:\n",
    "accuracy_avg = np.mean(accuracy_list)\n",
    "accuracy_std = np.std(accuracy_list)\n",
    "loss_avg = np.mean(loss_list)\n",
    "loss_std = np.std(loss_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "id": "1258983a-02ef-4bc8-954b-41693facd7c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Test Accuracy: 0.8089\n",
      "Standard Deviation Test Accuracy: 0.0162\n",
      "Average Test Loss: 0.3466\n",
      "Standard Deviation Test Loss: 0.0193\n"
     ]
    }
   ],
   "source": [
    "# Print the metrics:\n",
    "print('Average Test Accuracy:', round(accuracy_avg, 4))\n",
    "print('Standard Deviation Test Accuracy:', round(accuracy_std, 4))\n",
    "print('Average Test Loss:', round(loss_avg, 4))\n",
    "print('Standard Deviation Test Loss:', round(loss_std, 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0b5b0e7-aa86-4970-873d-6b91d4249758",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
